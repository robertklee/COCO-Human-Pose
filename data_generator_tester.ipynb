{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c0cfba6cd26d1ab26e4c3e83d23793ceb7168314b52ecf65aba49005d127e69c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hourglass import HourglassNet\n",
    "from constants import *\n",
    "\n",
    "h = HourglassNet(NUM_COCO_KEYPOINTS,DEFAULT_NUM_HG,INPUT_CHANNELS,INPUT_DIM,OUTPUT_DIM)\n",
    "train_df, val_df = h.load_and_filter_annotations(DEFAULT_TRAIN_ANNOT_PATH,DEFAULT_VAL_ANNOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename is a globally unique identifier among all train/val/test splits\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import pylab\n",
    "import coco_df\n",
    "from matplotlib.patches import Rectangle\n",
    "pylab.rcParams['figure.figsize'] = (30.0, 30.0)\n",
    "\n",
    "train_annot_path = DEFAULT_TRAIN_ANNOT_PATH\n",
    "val_annot_path = DEFAULT_VAL_ANNOT_PATH\n",
    "train_coco = COCO(train_annot_path) # load annotations for training set\n",
    "val_coco = COCO(val_annot_path) # load annotations for validation set\n",
    "\n",
    "df = coco_df.get_df(train_annot_path,val_annot_path)\n",
    "\n",
    "def display_img(annId):\n",
    "  # Determine if img exists and if it is in train or val set\n",
    "  img_df_rows = df.loc[df['ann_id'] == annId]\n",
    "  if len(img_df_rows) == 0:\n",
    "      print(f\"Image with ann id {annId} does not exist.\")\n",
    "      return\n",
    "  \n",
    "  coco = train_coco if img_df_rows['source'].iloc[0] == 0 else val_coco\n",
    "\n",
    "  # Get img id from file name\n",
    "  imgId = img_df_rows['src_set_image_id'].iloc[0]\n",
    "  img = coco.imgs[imgId]\n",
    "  I = io.imread(img['coco_url']) # load image from URL (no need to store image locally)\n",
    "\n",
    "  # load and display keypoints annotations\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.imshow(I)\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.imshow(I)\n",
    "  annIds = coco.getAnnIds(imgIds=[imgId])\n",
    "  anns = coco.loadAnns(annIds)\n",
    "  bbox= list(img_df_rows['bbox'])[0]\n",
    "  plt.gca().add_patch(Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],\n",
    "                  edgecolor='red',\n",
    "                  facecolor='none',\n",
    "                  lw=4))\n",
    "  coco.showAnns(anns)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY DATA GENERATOR CODE IN HERE SO YOU CAN WORK WITH A NOTEBOOK WITH DATA IN MEMORY\n",
    "\n",
    "# Holy resources:\n",
    "# https://github.com/virafpatrawala/COCO-Semantic-Segmentation/blob/master/COCOdataset_SemanticSegmentation_Demo.ipynb\n",
    "# https://mahmoudyusof.github.io/facial-keypoint-detection/data-generator/\n",
    "# https://blog.paperspace.com/data-augmentation-for-object-detection-building-input-pipelines/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import skimage.io as io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from constants import *\n",
    "\n",
    "# TODO: Data Augementation:\n",
    "# - bounding box varied through data augmentation 110% to 150%\n",
    "# - horizontal flips\n",
    "# - rotations\n",
    "# - brightness adjustments\n",
    "# - contrast\n",
    "# - noise/grain\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence): # inherit from Sequence to access multicore functionality: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "  def __init__(self, df, base_dir, input_dim, output_dim, num_hg_blocks, shuffle=False, batch_size=DEFAULT_BATCH_SIZE, online_fetch=False):\n",
    "    self.df = df                    # df of the the annotations we want\n",
    "    self.base_dir = base_dir        # where to read imgs from in collab runtime\n",
    "    self.input_dim = input_dim      # model requirement for input image dimensions\n",
    "    self.output_dim = output_dim    # dimesnions of output heatmap of model\n",
    "    self.num_hg_blocks = num_hg_blocks\n",
    "    self.shuffle = shuffle\n",
    "    self.batch_size = batch_size\n",
    "    self.online_fetch = online_fetch # If true, images will be loaded from url over network rather than filesystem\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  # after each epoch, shuffle indices so data order changes\n",
    "  def on_epoch_end(self):\n",
    "    self.indices = np.arange(len(self.df))\n",
    "    if self.shuffle:\n",
    "      np.random.shuffle(self.indices)\n",
    "\n",
    "  # number of batches (not number of examples)\n",
    "  def __len__(self):\n",
    "    return int(len(self.df) / self.batch_size)\n",
    "\n",
    "  def transform_image(self, img, bbox):\n",
    "    new_bbox = self.transform_bbox(bbox)\n",
    "    cropped_img = img.crop(box=new_bbox)\n",
    "    cropped_width, cropped_height = cropped_img.size\n",
    "    scaled_img = np.array(cropped_img)/255.0 # scale RGB channels to [0,1]\n",
    "    new_img = cv2.resize(scaled_img,self.input_dim,interpolation=cv2.INTER_LINEAR)\n",
    "    return new_img, cropped_width, cropped_height, new_bbox[0], new_bbox[1]\n",
    "  \n",
    "  def transform_bbox(self,bbox):\n",
    "    x,y,w,h = [i for i in bbox] # (x,y,w,h) anchored to top left\n",
    "    center_x = x+w/2\n",
    "    center_y = y+h/2\n",
    "    if w >= h:\n",
    "        new_w = w\n",
    "    else:\n",
    "        new_w = h * self.input_dim[0]/self.input_dim[1]\n",
    "    if w < h:\n",
    "        new_h = h\n",
    "    else:\n",
    "        new_h = w * self.input_dim[1]/self.input_dim[0]\n",
    "    new_w*=BBOX_SLACK # add slack to bbox\n",
    "    new_h*=BBOX_SLACK # add slack to bbox\n",
    "    new_x = center_x - new_w/2\n",
    "    new_y = center_y - new_h/2\n",
    "    return (round(new_x),round(new_y),round(new_x+new_w),round(new_y+new_h))\n",
    "\n",
    "  def transform_label(self,label, cropped_width, cropped_height,anchor_x,anchor_y):\n",
    "    label = [int(v) for v in label]\n",
    "    # adjust x/y coords to new resized img\n",
    "    transformed_label = []\n",
    "    for x, y, v in zip(*[iter(label)]*NUM_COCO_KP_ATTRBS):\n",
    "      x = round((x-anchor_x) * self.input_dim[0]/cropped_width)\n",
    "      y = round((y-anchor_y) * self.input_dim[1]/cropped_height)\n",
    "      # validate kps, throw away if out of bounds\n",
    "      # TODO: if kp is thrown away then we must update num_keypoints\n",
    "      if (x > self.input_dim[0] or x < 0) or (y > self.input_dim[1] or y < 0):\n",
    "        x,y,v = (0,0,0)\n",
    "      \n",
    "      transformed_label.append(x)\n",
    "      transformed_label.append(y)\n",
    "      transformed_label.append(v)\n",
    "    return np.asarray(transformed_label)\n",
    "\n",
    "  def generate_heatmaps(self,label):\n",
    "    heat_maps = np.zeros((*self.output_dim, NUM_COCO_KEYPOINTS))\n",
    "    for i in range(NUM_COCO_KEYPOINTS):\n",
    "      label_idx = i * NUM_COCO_KP_ATTRBS # index for label\n",
    "      if label[label_idx + (NUM_COCO_KP_ATTRBS-1)] == 0: # generate empty heatmap for unlabelled kp\n",
    "        continue\n",
    "      kpx = int(label[label_idx])\n",
    "      kpy = int(label[label_idx + 1])\n",
    "      heat_map = self.gaussian(np.zeros(self.input_dim), (kpx,kpy),HEATMAP_SIGMA)\n",
    "      heat_maps[:,:,i] = cv2.resize(heat_map,self.output_dim,interpolation=cv2.INTER_LINEAR) # downscale heatmap resolution\n",
    "    \n",
    "    return heat_maps\n",
    "\n",
    "  # This func is unmodified and ripped from: https://github.com/princeton-vl/pose-hg-train/blob/master/src/pypose/draw.py\n",
    "  def gaussian(self,img, pt, sigma):\n",
    "    # Draw a 2D gaussian\n",
    "\n",
    "    # Check that any part of the gaussian is in-bounds\n",
    "    ul = [int(pt[0] - 3 * sigma), int(pt[1] - 3 * sigma)]\n",
    "    br = [int(pt[0] + 3 * sigma + 1), int(pt[1] + 3 * sigma + 1)]\n",
    "    if (ul[0] > img.shape[1] or ul[1] >= img.shape[0] or\n",
    "            br[0] < 0 or br[1] < 0):\n",
    "        # If not, just return the image as is\n",
    "        return img\n",
    "\n",
    "    # Generate gaussian\n",
    "    size = 6 * sigma + 1\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:, np.newaxis]\n",
    "    x0 = y0 = size // 2\n",
    "    # The gaussian is not normalized, we want the center value to equal 1\n",
    "    g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "    # Usable gaussian range\n",
    "    g_x = max(0, -ul[0]), min(br[0], img.shape[1]) - ul[0]\n",
    "    g_y = max(0, -ul[1]), min(br[1], img.shape[0]) - ul[1]\n",
    "    # Image range\n",
    "    img_x = max(0, ul[0]), min(br[0], img.shape[1])\n",
    "    img_y = max(0, ul[1]), min(br[1], img.shape[0])\n",
    "\n",
    "    img[img_y[0]:img_y[1], img_x[0]:img_x[1]] = g[g_y[0]:g_y[1], g_x[0]:g_x[1]]\n",
    "    return img\n",
    " \n",
    "\n",
    "  # returns batch at index idx\n",
    "  def __getitem__(self, idx):\n",
    "    # Initialize Batch:\n",
    "    X = np.empty((self.batch_size, *self.input_dim, 3))\n",
    "    \n",
    "    # Order of last dimension: (heatmap for each kp) repeated num_hg_blocks times\n",
    "    y = np.empty((self.batch_size, *self.output_dim, NUM_COCO_KEYPOINTS))\n",
    "\n",
    "    kps = np.empty((self.batch_size,NUM_COCO_KP_ATTRBS*NUM_COCO_KEYPOINTS))\n",
    "\n",
    "    annIds = []\n",
    "\n",
    "    # get the indices of the requested batch\n",
    "    indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "    for i, data_index in enumerate(indices):\n",
    "      ann = self.df.loc[data_index]\n",
    "      img_path = os.path.join(self.base_dir,ann['path'])\n",
    "      \n",
    "      if self.online_fetch:\n",
    "        img = Image.fromarray(io.imread(ann['coco_url'])).convert('RGB') # bottleneck opening from URL\n",
    "      else:\n",
    "        img = Image.open(img_path).convert('RGB') # bottleneck opening from file system\n",
    "      \n",
    "      transformed_img, cropped_width, cropped_height, anchor_x, anchor_y = self.transform_image(img, ann['bbox'])\n",
    "      transformed_label = self.transform_label(ann['keypoints'],cropped_width,cropped_height,anchor_x,anchor_y)\n",
    "      heat_map_labels = self.generate_heatmaps(transformed_label)\n",
    "      X[i,] = transformed_img\n",
    "      y[i,] = heat_map_labels\n",
    "      kps[i,] = transformed_label\n",
    "      annIds.append(ann['ann_id'])\n",
    "      print(ann['coco_url'])\n",
    "    return X, y, kps, annIds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator(\n",
    "    df=val_df,\n",
    "    base_dir=DEFAULT_TRAIN_IMG_PATH,\n",
    "    input_dim=INPUT_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    num_hg_blocks=DEFAULT_NUM_HG,\n",
    "    shuffle=False,  \n",
    "    batch_size=1,\n",
    "    online_fetch=False)\n",
    "\n",
    "# Test the generator\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "\n",
    "from submodules.HeatMap import HeatMap # https://github.com/LinShanify/HeatMap\n",
    "\n",
    "start = time.time()\n",
    "X_batch, y_batch, kps_batch, annIds = generator[161]\n",
    "X,y,kps,annId = X_batch[0], y_batch[0], kps_batch[0], annIds[0] # take first example of batch\n",
    "print(\"Retrieving batch took: \",time.time() - start, \" s\")\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "xs = [x for i,x in enumerate(kps) if i %3 == 0]\n",
    "ys = [x for i,x in enumerate(kps) if i %3 == 1]\n",
    "\n",
    "plt.scatter(xs,ys)\n",
    "hm = HeatMap(X,y[:,:,1])\n",
    "hm.plot(transparency=0.5,show_axis=True,show_colorbar=True)\n",
    "\n",
    "display_img(annId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}